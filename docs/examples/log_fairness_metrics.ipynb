{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log fairness classification metrics to Neptune\n",
    "## Train your model and run predictions\n",
    "Let's train a model on a synthetic problem predict on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "TARGET_COLS = 'two_year_recid'\n",
    "NUMERICAL_FEATURE_COLS = ['age',\n",
    "                          'juv_fel_count','juv_misd_count','juv_other_count',\n",
    "                          'priors_count','jail_time']\n",
    "CATEGORICAL_FEATURE_COLS = ['sex','race',\n",
    "                            'c_charge_degree']\n",
    "FEATURE_NAMES = NUMERICAL_FEATURE_COLS+CATEGORICAL_FEATURE_COLS\n",
    "\n",
    "data = pd.read_csv('../data/processed/compas-scores-two-years-processed.csv')\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=1234)\n",
    "\n",
    "X_train, y_train = train[FEATURE_NAMES], train[TARGET_COLS]\n",
    "X_test, y_test = test[FEATURE_NAMES], test[TARGET_COLS]\n",
    "\n",
    "clf = LogisticRegression(random_state=1234)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = clf.predict_proba(X_test)\n",
    "test['recid_prediction_score'] = y_test_pred[:,1]\n",
    "test['recid_prediction_class'] = (test['recid_prediction_score'] >0.5).astype(int)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "neptune.init(project_qualified_name='USER_NAME/PROJECT_NAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send all fairness classification metrics to Neptune\n",
    "\n",
    "With just one function call you can log a lot of information.\n",
    "\n",
    "### Metrics:\n",
    "\n",
    "- true_positive_rate_difference\n",
    "- false_positive_rate_difference\n",
    "- false_omission_rate_difference \n",
    "- false_discovery_rate_difference, error_rate_difference\n",
    "- false_positive_rate_ratio, false_negative_rate_ratio, false_omission_rate_ratio\n",
    "- false_discovery_rate_ratio, error_rate_ratio, average_odds_difference\n",
    "- disparate_impact, statistical_parity_difference, equal_opportunity_difference \n",
    "- theil_index, between_group_theil_index, between_all_groups_theil_index\n",
    "- coefficient_of_variation, between_group_coefficient_of_variation, between_all_groups_coefficient_of_variation\n",
    "- generalized_entropy_index, between_group_generalized_entropy_index, between_all_groups_generalized_entropy_index\n",
    "   \n",
    "### Performance by group charts:\n",
    "\n",
    "- confusion matrix\n",
    "- TPR, TNR, FPR, FNR, PPV, NPV, FDR, FOR \n",
    "- ACC, error_rate, selection_rate, power\n",
    "- precision, recall\n",
    "- sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptunecontrib.monitoring.fairness import log_fairness_classification_metrics\n",
    "\n",
    "with neptune.create_experiment()\n",
    "    neptune.log_metric('roc_auc',roc_auc)\n",
    "    log_fairness_classification_metrics(test['two_year_recid'], test['recid_prediction_class'], \n",
    "                                        test['recid_prediction_score'], test[['race']],\n",
    "                                        favorable_label=0, unfavorable_label=1,\n",
    "                                        privileged_groups={'race':[3]}, unprivileged_groups={'race':[1,2,4,5,6]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now safely logged in Neptune.\n",
    "Check out [this experiment](https://ui.neptune.ai/jakub-czakon/model-fairness/e/MOD-92/logs). \n",
    "\n",
    "![fairness classification metrics](../_static/images/fairness_metrics.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog_metrics",
   "language": "python",
   "name": "blog_metrics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
