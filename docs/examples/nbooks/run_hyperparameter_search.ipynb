{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run skopt/hyperopt hyper parameter sweep in neptune\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "### Training and evaluation script\n",
    "We will assume that you have python script that runs model training and evaluation\n",
    "based on the parameters defined via neptune context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "import lightgbm as lgb\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ctx = neptune.Context()\n",
    "\n",
    "data = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target,\n",
    "                                                    test_size=0.2, random_state=1234)\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "params = {'boosting_type': ctx.params.boosting_type,\n",
    "          'objective': ctx.params.objective,\n",
    "          'num_class': ctx.params.num_class,\n",
    "          'num_leaves': ctx.params.num_leaves,\n",
    "          'max_depth': ctx.params.max_depth,\n",
    "          'learning_rate': ctx.params.learning_rate,\n",
    "          'feature_fraction': ctx.params.feature_fraction}\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=ctx.params.num_boost_round,\n",
    "                valid_sets=[lgb_train, lgb_eval],\n",
    "                valid_names=['train', 'valid'],\n",
    "                )\n",
    "\n",
    "eval_loss= gbm.best_score['valid']['multi_logloss']\n",
    "ctx.properties['eval_loss'] = eval_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the evaluation metric should be saved as a neptune property:\n",
    "\n",
    "```python\n",
    "ctx.properties['YOUR_EVALUATION_METRIC']=score\n",
    "```\n",
    "\n",
    "### Configuration file\n",
    "This is not strictly necessary but it makes things cleaner. \n",
    "It is a good idea to define hyperparameters and properties in a neptune configuration file.\n",
    "\n",
    "Let's call it `neptune.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project: neptune-ml/neptune-examples\n",
    "\n",
    "metric:\n",
    "  channel: 'eval_loss'\n",
    "  goal: minimize\n",
    "\n",
    "parameters:\n",
    "    boosting_type: 'gbdt'\n",
    "    objective: 'multiclass'\n",
    "    num_class: 3\n",
    "    num_boost_round: 10\n",
    "    learning_rate: 0.1\n",
    "    num_leaves: 10\n",
    "    max_depth: 10\n",
    "    feature_fraction: 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Optimize parameter sweep\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import neptune\n",
    "import skopt\n",
    "import neptunecontrib.hpo.utils as hp_utils\n",
    "import neptunecontrib.monitoring.skopt as sk_monitor\n",
    "\n",
    "ctx = neptune.Context()\n",
    "ctx.tags.append('skopt_forest_search')\n",
    "\n",
    "METRIC_CHANNEL_NAME = 'eval_loss'\n",
    "PROJECT_NAME = 'neptune-ml/neptune-examples'\n",
    "N_CALLS = 50\n",
    "N_RANDOM_STARTS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [skopt.space.Integer(10, 60, name='num_leaves'),\n",
    "         skopt.space.Integer(2, 30, name='max_depth'),\n",
    "         skopt.space.Real(0.1, 0.9, name='feature_fraction', prior='uniform')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@skopt.utils.use_named_args(space)\n",
    "def objective(**params):\n",
    "    return hp_utils.make_objective(params,\n",
    "                                   command=['neptune run --config neptune.yaml','train_evaluate.py'],\n",
    "                                   metric_channel_name=METRIC_CHANNEL_NAME,\n",
    "                                   project_name=PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define NeptuneMonitor to observe metrics during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = sk_monitor.NeptuneMonitor(ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run skopt optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = skopt.forest_minimize(objective, space, callback=[monitor],\n",
    "                                base_estimator='ET',\n",
    "                                n_calls=N_CALLS,\n",
    "                                n_random_starts=N_RANDOM_STARTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log best parameters and diagnostic charts to Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.channel_send(METRIC_CHANNEL_NAME, results.fun)\n",
    "sk_monitor.send_best_parameters(results, ctx)\n",
    "sk_monitor.send_plot_convergence(results, ctx)\n",
    "sk_monitor.send_plot_evaluations(results, ctx)\n",
    "sk_monitor.send_plot_objective(results, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperopt parameter sweap\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "from hyperopt import hp, tpe, fmin, Trials\n",
    "import neptune\n",
    "import skopt\n",
    "from sklearn.externals import joblib\n",
    "import neptunecontrib.hpo.utils as hp_utils\n",
    "import neptunecontrib.monitoring.skopt as sk_monitor\n",
    "\n",
    "ctx = neptune.Context()\n",
    "ctx.tags.append('tpe_search')\n",
    "\n",
    "METRIC_CHANNEL_NAME = 'eval_loss'\n",
    "PROJECT_NAME = 'neptune-ml/neptune-examples'\n",
    "TRIALS_PATH = 'trials.pkl'\n",
    "N_CALLS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define search space\n",
    "Normally you define your search space in hyperopt by simply creating a dict.\n",
    "However, we want to make sure that the names are in the same order to be able\n",
    "to do some formatting later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = OrderedDict(num_leaves=hp.choice('num_leaves', range(10, 60, 1)),\n",
    "                    max_depth=hp.choice('max_depth', range(2, 30, 1)),\n",
    "                    feature_fraction=hp.uniform('feature_fraction', 0.1, 0.9)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    return hp_utils.make_objective(params,\n",
    "                                   command=['neptune run --config neptune.yaml','train_evaluate.py'],\n",
    "                                   metric_channel_name=METRIC_CHANNEL_NAME,\n",
    "                                   project_name=PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run hyperopt optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "_ = fmin(objective, space, trials=trials, algo=tpe.suggest, max_evals=N_CALLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log best parameters and diagnostic charts to Neptune\n",
    "Convert `hyperopt.Trials` object into `scipy.optimize.OptimizeResult`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = hp_utils.hyperopt2skopt(trials, space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send parameters and diagnostic charts to neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.channel_send(METRIC_CHANNEL_NAME, results.fun)\n",
    "sk_monitor.send_runs(results, ctx)\n",
    "sk_monitor.send_best_parameters(results, ctx)\n",
    "sk_monitor.send_plot_convergence(results, ctx)\n",
    "sk_monitor.send_plot_evaluations(results, ctx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
